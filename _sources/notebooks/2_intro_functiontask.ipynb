{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c62095",
   "metadata": {},
   "source": [
    "# 2. FunctionTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a46960c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f6cd4",
   "metadata": {},
   "source": [
    "A `FunctionTask` is a `Task` that can be created from every *python* function by using *pydra* decorator: `pydra.mark.task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda8f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydra\n",
    "\n",
    "@pydra.mark.task\n",
    "def add_var(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443ab88",
   "metadata": {},
   "source": [
    "Once we decorate the function, we can create a pydra `Task` and specify the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d3c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = add_var(a=4, b=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc7e88",
   "metadata": {},
   "source": [
    "We can check the type of `task1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550f7a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydra.engine.task.FunctionTask"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e32010",
   "metadata": {},
   "source": [
    "and we can check if the task has correct values of `a` and `b`, they should be saved in the task `inputs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f67a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 4\n",
      "b = 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"a = {task1.inputs.a}\")\n",
    "print(f\"b = {task1.inputs.b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa537e6e",
   "metadata": {},
   "source": [
    "We can also check content of entire `inputs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2f05c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inputs(a=4, b=5, _func=b'\\x80\\x04\\x95\\xf1\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x0e_make_function\\x94\\x93\\x94(h\\x00\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x02K\\x00K\\x02K\\x02KCC\\x08|\\x00|\\x01\\x17\\x00S\\x00\\x94N\\x85\\x94)\\x8c\\x01a\\x94\\x8c\\x01b\\x94\\x86\\x94\\x8cN/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/ipykernel_53451/3542708107.py\\x94\\x8c\\x07add_var\\x94K\\x03C\\x02\\x00\\x02\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94N\\x8c\\x08__name__\\x94\\x8c\\x08__main__\\x94uNNNt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x12_function_setstate\\x94\\x93\\x94h\\x17}\\x94}\\x94(h\\x14h\\x0e\\x8c\\x0c__qualname__\\x94h\\x0e\\x8c\\x0f__annotations__\\x94}\\x94\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94N\\x8c\\n__module__\\x94h\\x15\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94u\\x86\\x94\\x86R0.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d053d",
   "metadata": {},
   "source": [
    "As you could see, `task.inputs` contains also information about the function, that is an inseparable part of the `FunctionTask`.\n",
    "\n",
    "Once we have the task with set input, we can run it. Since `Task` is a \"callable object\", we can use the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c11a83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f132d",
   "metadata": {},
   "source": [
    "As you can see, the result was returned right away, but we can also access it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa767298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195aa08",
   "metadata": {},
   "source": [
    "`Result` contains more than just an output, so if we want to get the task output, we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04414a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = task1.result()\n",
    "result.output.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e431dbd",
   "metadata": {},
   "source": [
    "And if we want to see the input that was used in the task, we can set an optional argument `return_inputs` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359f6a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'add_var.a': 4, 'add_var.b': 5},\n",
       " Result(output=Output(out=9), runtime=None, errored=False))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.result(return_inputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e96618",
   "metadata": {},
   "source": [
    "## Customizing output names\n",
    "Note, that \"out\" is the default name for the task output, but we can always customize it. There are two ways of doing it: using *python* function annotation and using another *pydra* decorator:\n",
    "\n",
    "Let's start from the function annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f268cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(sum_a_b=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing as ty\n",
    "\n",
    "@pydra.mark.task\n",
    "def add_var_an(a, b) -> {\"sum_a_b\": int}:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "task1a = add_var_an(a=4, b=5)\n",
    "task1a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14045503",
   "metadata": {},
   "source": [
    "The annotation might be very useful to specify the output names when the function returns multiple values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43d5a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(fractional=0.5, integer=3.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "def modf_an(a) -> {\"fractional\": ty.Any, \"integer\": ty.Any}:\n",
    "    import math\n",
    "    return math.modf(a)\n",
    "\n",
    "task2 = modf_an(a=3.5)\n",
    "task2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11adff65",
   "metadata": {},
   "source": [
    "The second way of customizing the output requires another decorator - `pydra.mark.annotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a97e55d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(fractional=0.5, integer=3.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate({\"return\": {\"fractional\": ty.Any, \"integer\": ty.Any}})\n",
    "def modf(a):\n",
    "    import math\n",
    "    return math.modf(a)\n",
    "\n",
    "task2a = modf(a=3.5)\n",
    "task2a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb3455",
   "metadata": {},
   "source": [
    "**Note, that the order of the pydra decorators is important!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb03f2",
   "metadata": {},
   "source": [
    "## Setting the input\n",
    "\n",
    "We don't have to provide the input when we create a task, we can always set it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41cc556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3 = add_var()\n",
    "task3.inputs.a = 4\n",
    "task3.inputs.b = 5\n",
    "task3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c4226",
   "metadata": {},
   "source": [
    "If we don't specify the input, `attr.NOTHING` will be used as the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7fef6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3a = add_var()\n",
    "task3a.inputs.a = 4\n",
    "\n",
    "# importing attr library, and checking the type pf `b`\n",
    "import attr\n",
    "task3a.inputs.b == attr.NOTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d420fe",
   "metadata": {},
   "source": [
    "And if we try to run the task, an error will be raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0311569b",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and '_Nothing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/ipykernel_53451/3698768266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtask3a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, submitter, plugin, plugin_kwargs, rerun, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# tasks without state could be run without a submitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/core.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, rerun, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/task.py\u001b[0m in \u001b[0;36m_run_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_func\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/ipykernel_53451/3542708107.py\u001b[0m in \u001b[0;36madd_var\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpydra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and '_Nothing'"
     ]
    }
   ],
   "source": [
    "task3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38729f",
   "metadata": {},
   "source": [
    "## Output directory and caching the results\n",
    "\n",
    "After running the task, we can check where the output directory with the results was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "162dee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/private/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/tmpohzakmia/FunctionTask_f926c0dbfce8e78f128ce0cea74cc05345738e965ff829c7fb3a932eb2712b24')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cbdba",
   "metadata": {},
   "source": [
    "Within the directory you can find the file with the results: `_result.pklz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a93a016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_task.pklz', '_result.pklz']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(task3.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cb4a9",
   "metadata": {},
   "source": [
    "But we can also provide the path where we want to store the results. If a path is provided for the cache directory, then pydra will use the cached results of a node instead of recomputing the result. Let's create a temporary directory and a specific subdirectory \"task4\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53239353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/tmpx9haz46h/task4\n"
     ]
    }
   ],
   "source": [
    "from tempfile import mkdtemp\n",
    "from pathlib import Path\n",
    "cache_dir_tmp = Path(mkdtemp()) / \"task4\"\n",
    "print(cache_dir_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017dd9a",
   "metadata": {},
   "source": [
    "Now we can pass this path to the argument of `FunctionTask` - `cache_dir`. To observe the execution time, we specify a function that is sleeping for 5s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90efd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "def add_var_wait(a, b):\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "    return a + b\n",
    "\n",
    "task4 = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859ff3b",
   "metadata": {},
   "source": [
    "If you're running the cell first time, it should take around 5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e05a3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4()\n",
    "task4.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72f090",
   "metadata": {},
   "source": [
    "We can check `output_dir` of our task, it should contain the path of `cache_dir_tmp` and the last part contains the name of the task class `FunctionTask` and the task checksum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6350460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/private/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/tmpx9haz46h/task4/FunctionTask_ebbf9c3d586c2dae364d20fc2643c76485099d048b8933d751fb3d1b76091803')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8651879",
   "metadata": {},
   "source": [
    "Let's see what happens when we defined identical task again with the same `cache_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d74102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4a = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp)\n",
    "task4a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d5000",
   "metadata": {},
   "source": [
    "This time the result should be ready right away! *pydra* uses available results and do not recompute the task.\n",
    "\n",
    "*pydra* not only checks for the results in `cache_dir`, but you can provide a list of other locations that should be checked. Let's create another directory that will be used as `cache_dir` and previous working directory will be used in `cache_locations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f875115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir_tmp_new = Path(mkdtemp()) / \"task4b\"\n",
    "\n",
    "task4b = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp_new, cache_locations=[cache_dir_tmp])\n",
    "task4b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991afa77",
   "metadata": {},
   "source": [
    "This time the results should be also returned quickly! And we can check that `task4b.output_dir` was not created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "424d6319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4b.output_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec762fa",
   "metadata": {},
   "source": [
    "If you want to rerun the task regardless having already the results, you can set `rerun` to `True`. The task will take several seconds and new `output_dir` will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03da7e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir_tmp_new = Path(mkdtemp()) / \"task4c\"\n",
    "\n",
    "task4c = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp_new, cache_locations=[cache_dir_tmp])\n",
    "task4c(rerun=True)\n",
    "\n",
    "task4c.output_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3c54d",
   "metadata": {},
   "source": [
    "If we update the input of the task, and run again, the new directory will be created and task will be recomputed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26315366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(output=Output(out=7), runtime=None, errored=False)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "task4b.inputs.a = 1\n",
    "print(task4b())\n",
    "print(task4b.output_dir.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450611f",
   "metadata": {},
   "source": [
    "and when we check the `output_dir`, we can see that it's different than last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92e5910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/private/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/tmpc9c_zna7/task4b/FunctionTask_59c8fd7fdc6be12f9ca29543a591e925d41ebf59fe98680b4471dd15b9822ebb')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4b.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dada6",
   "metadata": {},
   "source": [
    "This is because, the checksum changes when we change either input or function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a3b70",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "Create a task that take a list of numbers as an input and returns two fields: `mean` with the mean value and `std` with the standard deviation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "041b31c0",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(mean=2, std=0.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate({\"return\": {\"mean\": ty.Any, \"std\": ty.Any}})\n",
    "def mean_dev(my_list):\n",
    "    import statistics as st\n",
    "    return st.mean(my_list), st.stdev(my_list)\n",
    "\n",
    "my_task = mean_dev(my_list=[2, 2, 2])\n",
    "my_task()\n",
    "my_task.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3be37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your solution here (you can use statistics module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab74b7",
   "metadata": {},
   "source": [
    "## Using Audit\n",
    "\n",
    "*pydra* can record various run time information, including the workflow provenance, by setting `audit_flags` and the type of messengers. \n",
    "\n",
    "`AuditFlag.RESOURCE` allows you to monitor resource usage for the `Task`, while `AuditFlag.PROV` tracks the provenance of the `Task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e660e332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=Runtime(rss_peak_gb=0.0763359072265625, vms_peak_gb=34.04956436132812, cpu_peak_percent=100.4), errored=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydra.utils.messenger import AuditFlag, PrintMessenger\n",
    "\n",
    "task5 = add_var(a=4, b=5, audit_flags=AuditFlag.RESOURCE)\n",
    "task5()\n",
    "task5.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b39cd",
   "metadata": {},
   "source": [
    "One can turn on both audit flags using `AuditFlag.ALL`, and print the messages on the terminal using the `PrintMessenger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d5ac914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: ddb0b278174f48b69d8c14b2cf9195cb\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:07961cca4990484a88a78f8ea47b25b0\",\n",
      "  \"@type\": \"task\",\n",
      "  \"startedAtTime\": \"2022-06-30T02:53:19.253777\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 3f2cb217589146a88145d70c998a1345\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:c5ff018bcb6a4c6eb8b8a33a7d91add1\",\n",
      "  \"@type\": \"monitor\",\n",
      "  \"startedAtTime\": \"2022-06-30T02:53:19.485082\",\n",
      "  \"wasStartedBy\": \"uid:07961cca4990484a88a78f8ea47b25b0\"\n",
      "}\n",
      "id: 89c7fc108d8b40028e03bb5e993e4f7f\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:c5ff018bcb6a4c6eb8b8a33a7d91add1\",\n",
      "  \"endedAtTime\": \"2022-06-30T02:53:19.540318\",\n",
      "  \"wasEndedBy\": \"uid:07961cca4990484a88a78f8ea47b25b0\"\n",
      "}\n",
      "id: cb9b4795c87141e2ac4b6a64fd250e12\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"rss_peak_gb\": 0.07687759375,\n",
      "  \"vms_peak_gb\": 34.04956436132812,\n",
      "  \"cpu_peak_percent\": 105.2,\n",
      "  \"@id\": \"uid:838e19098dcd4671a4ed160ed5fabae9\",\n",
      "  \"@type\": \"runtime\",\n",
      "  \"prov:wasGeneratedBy\": \"uid:07961cca4990484a88a78f8ea47b25b0\"\n",
      "}\n",
      "id: edeb09ad3b9e4bf6aa22e657d55de405\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@type\": \"prov:Generation\",\n",
      "  \"entity_generated\": \"uid:838e19098dcd4671a4ed160ed5fabae9\",\n",
      "  \"hadActivity\": \"uid:c5ff018bcb6a4c6eb8b8a33a7d91add1\"\n",
      "}\n",
      "id: e006178ab4da4440bb50309994b951b7\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:07961cca4990484a88a78f8ea47b25b0\",\n",
      "  \"endedAtTime\": \"2022-06-30T02:53:19.540693\",\n",
      "  \"errored\": false\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=Runtime(rss_peak_gb=0.07687759375, vms_peak_gb=34.04956436132812, cpu_peak_percent=105.2), errored=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task5 = add_var(a=4, b=5, audit_flags=AuditFlag.ALL, messengers=PrintMessenger())\n",
    "task5()\n",
    "task5.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee0985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "source_map": [
   12,
   16,
   27,
   32,
   38,
   42,
   44,
   48,
   50,
   54,
   57,
   61,
   63,
   69,
   71,
   75,
   77,
   81,
   84,
   88,
   90,
   97,
   107,
   111,
   119,
   123,
   132,
   136,
   142,
   147,
   151,
   158,
   162,
   166,
   172,
   174,
   178,
   181,
   185,
   190,
   194,
   202,
   206,
   209,
   213,
   215,
   219,
   222,
   228,
   233,
   237,
   239,
   243,
   250,
   254,
   258,
   262,
   264,
   268,
   273,
   287,
   289,
   297,
   303,
   307,
   313
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}